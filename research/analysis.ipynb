{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfcb4db5",
   "metadata": {},
   "source": [
    "# Instagram Influencer Quality Analysis Notebook\n",
    "\n",
    "This notebook is used to collect and analyze real Instagram data for evaluating influencer quality.  \n",
    "It pulls information directly from Bright Data’s scraping datasets and allows you to inspect profiles, posts, reels and comments at scale.\n",
    "\n",
    "The goal of this notebook is to:\n",
    "- retrieve fresh data for any Instagram creator,\n",
    "- analyze posting patterns, engagement and audience signals,\n",
    "- compare influencers across multiple metrics,\n",
    "- and validate whether their content looks authentic or artificially boosted.\n",
    "\n",
    "All scraping calls are done through Bright Data’s Dataset API and the helper functions below provide a clean interface for triggering snapshots and downloading results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbe692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing import Optional, List, Any, Dict\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "BASE_URL = \"https://api.brightdata.com\"\n",
    "INSTAGRAM_DATASET_ID = \"gd_l1vikfch901nx3by4\"   \n",
    "BRIGHTDATA_TOKEN = os.getenv(\"BRIGHTDATA_API_TOKEN\")\n",
    "INSTAGRAM_POSTS_DATASET_ID = \"gd_lk5ns7kz21pck8jpis\"\n",
    "INSTAGRAM_REELS_DATASET_ID = \"gd_lyclm20il4r5helnj\"  \n",
    "INSTAGRAM_COMMENTS_DATASET_ID = \"gd_ltppn085pokosxh13\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {BRIGHTDATA_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f57c36",
   "metadata": {},
   "source": [
    "## Bright Data Helper Functions for Instagram Scraping\n",
    "\n",
    "This section defines a small set of reusable helper functions that interact with Bright Data’s Instagram datasets.  \n",
    "Each function triggers a snapshot, polls until it is ready, and then downloads the final JSON results.\n",
    "\n",
    "Included functions:\n",
    "- `fetch_instagram_profile_snapshot()` — collect profile metadata by username  \n",
    "- `fetch_instagram_posts_by_url()` — collect posts within a date range  \n",
    "- `fetch_instagram_reels_by_url()` — collect Reels within a date range  \n",
    "- `fetch_instagram_comments_by_url()` — collect comments for a specific post or reel  \n",
    "\n",
    "All functions use a shared internal helper `_run_brightdata_snapshot()` to avoid duplication and keep the logic consistent across datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e4ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_brightdata_snapshot(\n",
    "    trigger_body: Dict[str, Any],\n",
    "    trigger_params: Dict[str, Any],\n",
    "    base_url: str,\n",
    "    poll_interval: int,\n",
    "    timeout: int,\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Internal helper to trigger a Bright Data snapshot, poll for completion,\n",
    "    and download the resulting JSON data.\n",
    "    \"\"\"\n",
    "    # 1. Trigger the snapshot\n",
    "    trigger_resp = requests.post(\n",
    "        f\"{base_url}/datasets/v3/trigger\",\n",
    "        headers=headers,\n",
    "        params=trigger_params,\n",
    "        json=trigger_body,\n",
    "        timeout=30,\n",
    "    )\n",
    "    print(\"Trigger raw text:\", trigger_resp.text)\n",
    "    trigger_resp.raise_for_status()\n",
    "\n",
    "    trigger_json = trigger_resp.json()\n",
    "    snapshot_id = trigger_json.get(\"snapshot_id\")\n",
    "    if not snapshot_id:\n",
    "        raise RuntimeError(f\"No snapshot_id in trigger response: {trigger_json}\")\n",
    "\n",
    "    print(\"Trigger response status:\", trigger_resp.status_code)\n",
    "    print(\"Snapshot ID:\", snapshot_id)\n",
    "\n",
    "    # 2. Poll snapshot progress until it is ready\n",
    "    progress_url = f\"{base_url}/datasets/v3/progress/{snapshot_id}\"\n",
    "    deadline = time.time() + timeout\n",
    "\n",
    "    while True:\n",
    "        progress_resp = requests.get(progress_url, headers=headers, timeout=30)\n",
    "        print(\"Progress raw:\", progress_resp.text[:300])\n",
    "        progress_resp.raise_for_status()\n",
    "\n",
    "        progress_json = progress_resp.json()\n",
    "        status = progress_json.get(\"status\")\n",
    "        print(\"Current status:\", status)\n",
    "\n",
    "        if status in {\"done\", \"completed\", \"ready\"}:\n",
    "            print(\"Snapshot is ready!\")\n",
    "            break\n",
    "\n",
    "        if status in {\"failed\", \"error\"}:\n",
    "            raise RuntimeError(\n",
    "                f\"Snapshot failed with status='{status}'. Response: {progress_json}\"\n",
    "            )\n",
    "\n",
    "        if time.time() > deadline:\n",
    "            raise TimeoutError(\n",
    "                f\"Snapshot {snapshot_id} timed out after {timeout}s. Last status: {status}\"\n",
    "            )\n",
    "\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "    # 3. Download the snapshot contents as JSON\n",
    "    download_url = f\"{base_url}/datasets/v3/snapshot/{snapshot_id}\"\n",
    "    download_resp = requests.get(\n",
    "        download_url,\n",
    "        headers=headers,\n",
    "        params={\"format\": \"json\"},\n",
    "        timeout=60,\n",
    "    )\n",
    "    download_resp.raise_for_status()\n",
    "\n",
    "    data = download_resp.json()\n",
    "    print(\n",
    "        f\"Downloaded {len(data) if isinstance(data, list) else 'unknown number of'} records.\"\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def fetch_instagram_profile_snapshot(\n",
    "    user_name: str,\n",
    "    dataset_id: str = INSTAGRAM_DATASET_ID,\n",
    "    base_url: str = BASE_URL,\n",
    "    poll_interval: int = 5,\n",
    "    timeout: int = 300,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trigger an Instagram snapshot, wait until it is fully processed,\n",
    "    and download the resulting JSON data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_name : str\n",
    "        Instagram username without '@', e.g. \"zoobarcelona\".\n",
    "    dataset_id : str\n",
    "        Bright Data dataset ID for Instagram.\n",
    "    base_url : str\n",
    "        Base Bright Data API URL.\n",
    "    poll_interval : int\n",
    "        Time in seconds between progress checks.\n",
    "    timeout : int\n",
    "        Maximum time in seconds to wait for snapshot to finish.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        data - parsed JSON from the snapshot.\n",
    "    \"\"\"\n",
    "    trigger_body = {\n",
    "        \"input\": [{\"user_name\": user_name}],\n",
    "    }\n",
    "\n",
    "    trigger_params = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"notify\": \"false\",\n",
    "        \"include_errors\": \"true\",\n",
    "        \"type\": \"discover_new\",\n",
    "        \"discover_by\": \"user_name\",\n",
    "    }\n",
    "\n",
    "    data = _run_brightdata_snapshot(\n",
    "        trigger_body=trigger_body,\n",
    "        trigger_params=trigger_params,\n",
    "        base_url=base_url,\n",
    "        poll_interval=poll_interval,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def fetch_instagram_posts_by_url(\n",
    "    url: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    num_of_posts: Optional[int] = None,\n",
    "    post_type: Optional[str] = None,\n",
    "    posts_to_not_include: Optional[List[str]] = None,\n",
    "    dataset_id: str = INSTAGRAM_POSTS_DATASET_ID,\n",
    "    base_url: str = BASE_URL,\n",
    "    poll_interval: int = 5,\n",
    "    timeout: int = 300,\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Trigger an Instagram posts snapshot for a single profile URL, wait\n",
    "    until it is fully processed, and download the resulting JSON data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Full Instagram profile URL, e.g. \"https://www.instagram.com/meta/\".\n",
    "    start_date : str\n",
    "        Start date filter for posts, as a string, e.g. \"01-01-2025\".\n",
    "        (Use the same format as configured in your Bright Data dataset.)\n",
    "    end_date : str\n",
    "        End date filter for posts, e.g. \"03-01-2025\".\n",
    "    num_of_posts : int, optional\n",
    "        Maximum number of posts to fetch. If None, the dataset default is used.\n",
    "    post_type : str, optional\n",
    "        Post type filter, e.g. \"Post\", \"Reel\", or \"\" for all.\n",
    "    posts_to_not_include : list of str, optional\n",
    "        List of post IDs that should be excluded.\n",
    "    dataset_id : str\n",
    "        Bright Data dataset ID for Instagram posts.\n",
    "    base_url : str\n",
    "        Base Bright Data API URL.\n",
    "    poll_interval : int\n",
    "        Time in seconds between progress checks.\n",
    "    timeout : int\n",
    "        Maximum time in seconds to wait for snapshot to finish.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        data - parsed JSON from the snapshot.\n",
    "    \"\"\"\n",
    "    input_payload: dict = {\n",
    "        \"url\": url,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "    }\n",
    "\n",
    "    if num_of_posts is not None:\n",
    "        input_payload[\"num_of_posts\"] = num_of_posts\n",
    "\n",
    "    if post_type is not None:\n",
    "        input_payload[\"post_type\"] = post_type\n",
    "\n",
    "    if posts_to_not_include:\n",
    "        input_payload[\"posts_to_not_include\"] = posts_to_not_include\n",
    "\n",
    "    trigger_body = {\n",
    "        \"input\": [input_payload],\n",
    "    }\n",
    "\n",
    "    trigger_params = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"notify\": \"false\",\n",
    "        \"include_errors\": \"true\",\n",
    "        \"type\": \"discover_new\",\n",
    "        \"discover_by\": \"url\",\n",
    "    }\n",
    "\n",
    "    data = _run_brightdata_snapshot(\n",
    "        trigger_body=trigger_body,\n",
    "        trigger_params=trigger_params,\n",
    "        base_url=base_url,\n",
    "        poll_interval=poll_interval,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def fetch_instagram_reels_by_url(\n",
    "    url: str,\n",
    "    start_date: str = \"\",\n",
    "    end_date: str = \"\",\n",
    "    dataset_id: str = INSTAGRAM_REELS_DATASET_ID,\n",
    "    base_url: str = BASE_URL,\n",
    "    poll_interval: int = 5,\n",
    "    timeout: int = 300,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trigger an Instagram Reels snapshot for a single profile URL, wait\n",
    "    until it is fully processed, and download the resulting JSON data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Full Instagram profile URL, e.g. \"https://www.instagram.com/espn\".\n",
    "    start_date : str\n",
    "        Optional start date filter for reels. Format must match the dataset.\n",
    "        If empty string, no filter is applied.\n",
    "    end_date : str\n",
    "        Optional end date filter for reels. If empty string, no filter is applied.\n",
    "    dataset_id : str\n",
    "        Bright Data dataset ID for Instagram Reels.\n",
    "    base_url : str\n",
    "        Base Bright Data API URL.\n",
    "    poll_interval : int\n",
    "        Time in seconds between progress checks.\n",
    "    timeout : int\n",
    "        Maximum time in seconds to wait for snapshot to finish.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data - parsed JSON from the snapshot.\n",
    "    \"\"\"\n",
    "    input_payload = {\n",
    "        \"url\": url,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "    }\n",
    "\n",
    "    trigger_body = {\n",
    "        \"input\": [input_payload],\n",
    "    }\n",
    "\n",
    "    trigger_params = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"notify\": \"false\",\n",
    "        \"include_errors\": \"true\",\n",
    "        \"type\": \"discover_new\",\n",
    "        \"discover_by\": \"url\",\n",
    "    }\n",
    "\n",
    "    data = _run_brightdata_snapshot(\n",
    "        trigger_body=trigger_body,\n",
    "        trigger_params=trigger_params,\n",
    "        base_url=base_url,\n",
    "        poll_interval=poll_interval,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "def fetch_instagram_comments_by_url(\n",
    "    url: str,\n",
    "    dataset_id: str = INSTAGRAM_COMMENTS_DATASET_ID,\n",
    "    base_url: str = BASE_URL,\n",
    "    poll_interval: int = 5,\n",
    "    timeout: int = 300,\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Trigger an Instagram comments snapshot for a single post URL, wait\n",
    "    until it is fully processed, and download the resulting JSON data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Full Instagram post or reel URL, e.g.\n",
    "        \"https://www.instagram.com/cats_of_instagram/reel/C4GLo_eLO2e/\".\n",
    "    dataset_id : str\n",
    "        Bright Data dataset ID for Instagram comments.\n",
    "    base_url : str\n",
    "        Base Bright Data API URL.\n",
    "    poll_interval : int\n",
    "        Time in seconds between progress checks.\n",
    "    timeout : int\n",
    "        Maximum time in seconds to wait for snapshot to finish.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        data - parsed JSON from the snapshot.\n",
    "    \"\"\"\n",
    "    input_payload = {\n",
    "        \"url\": url,\n",
    "    }\n",
    "\n",
    "    trigger_body = {\n",
    "        \"input\": [input_payload],\n",
    "    }\n",
    "\n",
    "    trigger_params = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"notify\": \"false\",\n",
    "        \"include_errors\": \"true\",\n",
    "    }\n",
    "\n",
    "    data = _run_brightdata_snapshot(\n",
    "        trigger_body=trigger_body,\n",
    "        trigger_params=trigger_params,\n",
    "        base_url=base_url,\n",
    "        poll_interval=poll_interval,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f119b",
   "metadata": {},
   "source": [
    "## Examples of calls\n",
    "\n",
    "```\n",
    "data = fetch_instagram_profile_snapshot(\"zoobarcelona\")\n",
    "\n",
    "posts_data = fetch_instagram_posts_by_url(\n",
    "    url=\"https://www.instagram.com/zoobarcelona/\",\n",
    "    start_date=\"08-21-2025\",  # 3 months back from today, example\n",
    "    end_date=\"11-21-2025\",\n",
    "    post_type=\"Post\",\n",
    ")\n",
    "\n",
    "reels_data = fetch_instagram_reels_by_url(\n",
    "    url=\"https://www.instagram.com/zoobarcelona\",\n",
    "    start_date=\"10-21-2025\",\n",
    "    end_date=\"11-21-2025\",\n",
    ")\n",
    "\n",
    "comments_data = fetch_instagram_comments_by_url(\n",
    "    url=\"https://www.instagram.com/cats_of_instagram/reel/C4GLo_eLO2e/\"\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221eefb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "URLS = [\n",
    "    \"https://www.instagram.com/biancafrombrooklyn\",\n",
    "    \"https://www.instagram.com/emscakesntreats\",\n",
    "    \"https://www.instagram.com/aya_eats_\",\n",
    "    \"https://www.instagram.com/bigdoughenergy/\",\n",
    "    \"https://www.instagram.com/sorteddelightsby_lini\",\n",
    "    \"https://www.instagram.com/breadology101\",\n",
    "\n",
    "    \"https://www.instagram.com/theclevercarrot\",\n",
    "    \"https://www.instagram.com/BrooklynSourdough\",\n",
    "    \"https://www.instagram.com/riseandloaf_sourdoughco\",\n",
    "    \"https://www.instagram.com/BlondieandRye\",\n",
    "    \"https://www.instagram.com/Maurizio\",\n",
    "    \"https://www.instagram.com/october_farms\",\n",
    "    \"https://www.instagram.com/the.sourdough.baker\",\n",
    "    \"https://www.instagram.com/bookroad.sourdough.co\",\n",
    "    \"https://www.instagram.com/giasbatch\",\n",
    "    \"https://www.instagram.com/amybakesbread\",\n",
    "\n",
    "    \"https://www.instagram.com/artisanbryan\",\n",
    "    \"https://www.instagram.com/thebreadahead\",\n",
    "    \"https://www.instagram.com/nyc.breadgirl\",\n",
    "    \"https://www.instagram.com/oliver_the_baker\",\n",
    "]\n",
    "\n",
    "\n",
    "def extract_username(url: str) -> str:\n",
    "    \"\"\"Extract username from Instagram URL.\"\"\"\n",
    "    path = urlparse(url).path\n",
    "    # /username/, /username → strip slashes\n",
    "    username = path.strip(\"/\")\n",
    "\n",
    "    return username\n",
    "\n",
    "\n",
    "def collect_profiles(urls):\n",
    "    \"\"\"Fetch profile snapshots for unique usernames.\"\"\"\n",
    "    unique_usernames = {extract_username(u) for u in urls}\n",
    "\n",
    "    results = []\n",
    "    for username in unique_usernames:\n",
    "        try:\n",
    "            print(f\"Fetching: {username}\")\n",
    "            profile = fetch_instagram_profile_snapshot(username)\n",
    "            if profile:\n",
    "                results.append(profile)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {username}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "profiles = collect_profiles(URLS)\n",
    "\n",
    "with open(\"profiles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(profiles, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved {len(profiles)} profiles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e9235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11aae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47ec00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "def _pick_existing_key(sample: Dict[str, Any], candidates: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Try to find the first key in candidates that exists in the sample dict.\n",
    "    Returns the key name or None.\n",
    "    \"\"\"\n",
    "    for key in candidates:\n",
    "        if key in sample:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_posts_dataframe(posts_data: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert raw Bright Data Instagram posts JSON into a normalized DataFrame.\n",
    "\n",
    "    The function uses the following mapping:\n",
    "      - posted_at:  content timestamp from 'date_posted'\n",
    "      - scraped_at: snapshot timestamp from 'timestamp' (Bright Data metadata)\n",
    "      - likes:      from 'likes'\n",
    "      - comments:   from 'num_comments'\n",
    "      - caption:    from 'description'\n",
    "      - caption_length: length of caption text\n",
    "      - post_url:   from 'url'\n",
    "      - post_id:    from 'post_id'\n",
    "      - content_type: from 'content_type'\n",
    "      - followers:  from 'followers' (per-row, last seen value)\n",
    "    \"\"\"\n",
    "    if not posts_data:\n",
    "        raise ValueError(\"posts_data is empty\")\n",
    "\n",
    "    df = pd.DataFrame(posts_data)\n",
    "\n",
    "    # Content timestamp: when the post was actually published\n",
    "    if \"date_posted\" in df.columns:\n",
    "        df[\"posted_at\"] = pd.to_datetime(\n",
    "            df[\"date_posted\"], utc=True, errors=\"coerce\"\n",
    "        ).dt.tz_convert(None)  # make tz-naive\n",
    "    else:\n",
    "        df[\"posted_at\"] = pd.NaT\n",
    "\n",
    "    # Snapshot timestamp: when Bright Data collected the data\n",
    "    if \"timestamp\" in df.columns:\n",
    "        df[\"scraped_at\"] = pd.to_datetime(\n",
    "            df[\"timestamp\"], utc=True, errors=\"coerce\"\n",
    "        ).dt.tz_convert(None)\n",
    "    else:\n",
    "        df[\"scraped_at\"] = pd.NaT\n",
    "\n",
    "    # Basic engagement metrics\n",
    "    if \"likes\" in df.columns:\n",
    "        df[\"likes\"] = pd.to_numeric(df[\"likes\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"likes\"] = None\n",
    "\n",
    "    if \"num_comments\" in df.columns:\n",
    "        df[\"comments\"] = pd.to_numeric(df[\"num_comments\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"comments\"] = None\n",
    "\n",
    "    # Caption text and its length\n",
    "    if \"description\" in df.columns:\n",
    "        df[\"caption\"] = df[\"description\"].fillna(\"\").astype(str)\n",
    "    else:\n",
    "        df[\"caption\"] = \"\"\n",
    "\n",
    "    df[\"caption_length\"] = df[\"caption\"].str.len()\n",
    "\n",
    "    # Basic identifiers / URLs\n",
    "    if \"url\" in df.columns:\n",
    "        df[\"post_url\"] = df[\"url\"].astype(str)\n",
    "\n",
    "    if \"post_id\" in df.columns:\n",
    "        df[\"post_id\"] = df[\"post_id\"].astype(str)\n",
    "\n",
    "    if \"content_type\" in df.columns:\n",
    "        df[\"content_type\"] = df[\"content_type\"].astype(str)\n",
    "\n",
    "    if \"followers\" in df.columns:\n",
    "        df[\"followers\"] = pd.to_numeric(df[\"followers\"], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def summarize_post_engagement(\n",
    "    df: pd.DataFrame,\n",
    "    followers_count: int | None = None,\n",
    "    days: int = 90,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute simple engagement stats for the last N days.\n",
    "\n",
    "    Uses the 'posted_at' column (tz-naive) as the post timestamp.\n",
    "    \"\"\"\n",
    "    if \"posted_at\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'posted_at' column\")\n",
    "\n",
    "    cutoff = datetime.utcnow() - timedelta(days=days)\n",
    "\n",
    "    recent = df[df[\"posted_at\"] >= cutoff].copy()\n",
    "\n",
    "    if recent.empty:\n",
    "        return {\n",
    "            \"posts_in_period\": 0,\n",
    "            \"avg_likes\": 0,\n",
    "            \"avg_comments\": 0,\n",
    "            \"engagement_rate_avg\": None,\n",
    "        }\n",
    "\n",
    "    avg_likes = recent[\"likes\"].mean()\n",
    "    avg_comments = recent[\"comments\"].mean()\n",
    "\n",
    "    if followers_count is None and \"followers\" in recent.columns:\n",
    "        followers_count = recent[\"followers\"].dropna().iloc[-1] if not recent[\"followers\"].dropna().empty else None\n",
    "\n",
    "    if followers_count and followers_count > 0:\n",
    "        recent[\"engagement_rate\"] = (recent[\"likes\"] + recent[\"comments\"]) / followers_count\n",
    "        engagement_rate_avg = recent[\"engagement_rate\"].mean()\n",
    "    else:\n",
    "        engagement_rate_avg = None\n",
    "\n",
    "    return {\n",
    "        \"posts_in_period\": int(len(recent)),\n",
    "        \"avg_likes\": float(avg_likes) if pd.notna(avg_likes) else 0,\n",
    "        \"avg_comments\": float(avg_comments) if pd.notna(avg_comments) else 0,\n",
    "        \"engagement_rate_avg\": float(engagement_rate_avg) if engagement_rate_avg is not None else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbde11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_plot = posts_df.sort_values(\"posted_at\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df_plot[\"posted_at\"], df_plot[\"likes\"])\n",
    "plt.title(\"Likes over time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Likes\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wykra-api-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
