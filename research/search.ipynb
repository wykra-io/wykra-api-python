{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e644cde3",
   "metadata": {},
   "source": [
    "# Instagram profile discovery via Google & Perplexity\n",
    "\n",
    "This notebook demonstrates four ways to discover real Instagram profiles for a specific niche and location:\n",
    "\n",
    "1) Google → Instagram search (Bright Data Google SERP dataset):  \n",
    "   Triggers a SERP job with targeted `site:instagram.com ...` queries, waits for the snapshot, and downloads JSON results.\n",
    "\n",
    "2) Google → Instagram search (Bright Data AI Mode Google dataset):  \n",
    "   Uses a short natural-language prompt (instead of a strict keyword) to guide discovery, then fetches results as JSON.\n",
    "\n",
    "3) Perplexity → Instagram search (Bright Data Web Scrapers Library):  \n",
    "   Runs a Perplexity-powered search with a concise prompt and retrieves the JSON output for post-processing.\n",
    "\n",
    "4) Direct call to Perplexity (OpenRouter):  \n",
    "   Calls a Perplexity online model via OpenRouter and extracts only profile URLs from the plain-text response.\n",
    "\n",
    "\n",
    "Prerequisites\n",
    "- Environment variables:\n",
    "  - `BRIGHTDATA_API_TOKEN` for Bright Data dataset calls\n",
    "  - `OPENROUTER_API_KEY` for OpenRouter / Perplexity calls\n",
    "- Python libs: `requests`, `pydantic-ai` (with OpenRouter provider)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbe692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1379dd77",
   "metadata": {},
   "source": [
    "## 1. Google → Instagram search (Bright Data Google SERP dataset, targeted Google query)\n",
    "\n",
    "This code sends a targeted Google query (e.g., `site:instagram.com \"AI tools\"`) to the Bright Data Google SERP dataset, waits until the snapshot is fully processed, and then downloads the results as JSON.  \n",
    "\n",
    "`trigger_body` defines what exactly the Bright Data SERP dataset should search for.  \n",
    "- `url` — the Google domain to query.  \n",
    "- `keyword` — the full Google search string; here we limit results to Instagram profiles using `site:instagram.com` plus niche terms.  \n",
    "- `language` — Google interface language.  \n",
    "- `country` — the geographic region used for SERP results.  \n",
    "- `start_page` / `end_page` — how many Google results pages to scrape.\n",
    "\n",
    "This block tells Bright Data to run a targeted Google search and return up to 5 pages of results.\n",
    "\n",
    "Examples of keywords:\n",
    "- site:instagram.com \"sustainable fashion\" \"Europe\"\n",
    "- site:instagram.com \"indie maker\" OR \"solopreneur\" \"reels\"\n",
    "- site:instagram.com \"AI tools\" OR \"data engineer\" OR \"#buildinpublic\"\n",
    "- site:instagram.com \"nocode\" \"startup founder\" \"reels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dafeafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json, pathlib\n",
    "\n",
    "API_KEY = os.getenv(\"BRIGHTDATA_API_TOKEN\")\n",
    "DATASET_ID = \"gd_mfz5x93lmsjjjylob\"\n",
    "BASE_URL = \"https://api.brightdata.com\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\n",
    "# Trigger the Google SERP dataset run\n",
    "trigger_body = [\n",
    "    {\n",
    "        \"url\": \"https://www.google.com/\",\n",
    "        \"keyword\": (\n",
    "            'site:instagram.com (\"sourdough\" OR \"sourdough bread\" OR \"starter\") '\n",
    "            '(\"NYC\" OR \"New York\" OR \"Brooklyn\" OR \"Manhattan\" OR \"Queens\" OR \"Bronx\") '\n",
    "            '(\"bio\" OR \"profile\" OR \"baker\") -restaurant -shop -bakery -menu -delivery'\n",
    "        ),\n",
    "        \"language\": \"en\",\n",
    "        \"country\": \"US\",\n",
    "        \"start_page\": 1,\n",
    "        \"end_page\": 2\n",
    "    }\n",
    "]\n",
    "# other exapple for keyword param:\n",
    "# site:instagram.com \"sourdough\" \"New York\"\n",
    "# site:instagram.com \"bread baking\" \"NYC\"\n",
    "# site:instagram.com \"artisan baker\" \"New York\"\n",
    "# site:instagram.com \"home baker\" \"NYC\" \"sourdough\"\n",
    "# site:instagram.com \"baker\" \"Brooklyn\"\n",
    "# site:instagram.com \"sourdough bakery\" \"Manhattan\"\n",
    "# site:instagram.com \"micro bakery\" \"New York\"\n",
    "# site:instagram.com \"bagels\" \"NYC\"\n",
    "\n",
    "trigger_resp = requests.post(\n",
    "    f\"{BASE_URL}/datasets/v3/trigger\",\n",
    "    headers=headers,\n",
    "    params={\"dataset_id\": DATASET_ID, \"include_errors\": \"true\"},\n",
    "    json=trigger_body,\n",
    ")\n",
    "trigger_resp.raise_for_status()\n",
    "print(\"Trigger raw text:\", trigger_resp.text)\n",
    "print(\"Trigger response:\", trigger_resp.status_code, trigger_resp.text)\n",
    "snapshot_id = trigger_resp.json().get(\"snapshot_id\")\n",
    "\n",
    "# Poll progress until ready\n",
    "progress_url = f\"{BASE_URL}/datasets/v3/progress/{snapshot_id}\"\n",
    "\n",
    "while True:\n",
    "    r = requests.get(progress_url, headers=headers)\n",
    "    print(\"Progress raw:\", r.text[:300])\n",
    "\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "    status = j.get(\"status\")\n",
    "\n",
    "    if status in {\"done\", \"completed\", \"ready\"}:\n",
    "        print(\"Snapshot ready!\")\n",
    "        break\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "# Download results as JSON and save to file\n",
    "download_url = f\"{BASE_URL}/datasets/v3/snapshot/{snapshot_id}\"\n",
    "\n",
    "resp = requests.get(\n",
    "    download_url,\n",
    "    headers=headers,\n",
    "    params={\"format\": \"json\"},\n",
    ")\n",
    "\n",
    "resp.raise_for_status()\n",
    "\n",
    "data = resp.json()\n",
    "\n",
    "path = pathlib.Path(\"serp_results_1.json\")\n",
    "with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94f42e",
   "metadata": {},
   "source": [
    "## 2. Google → Instagram search (Bright Data AI Mode Google dataset, human language prompt)\n",
    "\n",
    "This code triggers an AI-Mode Google dataset run with a natural-language prompt, polls progress and downloads results as JSON. Instead of passing a strict keyword string, you write a short instruction (prompt) describing what to find and Bright Data’s AI-Mode performs the Google-style discovery for you.\n",
    "\n",
    "Prompt examples:\n",
    "- Find Instagram profiles of European sustainable-fashion creators. Use the Google query: site:instagram.com \"sustainable fashion\" \"Europe\". Return profile URLs only.\n",
    "- Find Instagram creators who are indie makers or solopreneurs posting reels. Use: site:instagram.com \"indie maker\" OR \"solopreneur\" \"reels\". Return profile URLs only.\n",
    "- Find Instagram profiles related to AI tools or data engineering. Use: site:instagram.com \"AI tools\" OR \"data engineer\" OR \"#buildinpublic\". Return profile URLs only.\n",
    "- Find Instagram profiles of startup founders who work with nocode and post reels. Use: site:instagram.com \"nocode\" \"startup founder\" \"reels\". Return profile URLs only.\n",
    "\n",
    "Tip: keep the prompt concise, include site:instagram.com and your niche terms and ask explicitly for profile URLs only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json, pathlib, requests\n",
    "\n",
    "API_KEY = os.getenv(\"BRIGHTDATA_API_TOKEN\")  \n",
    "DATASET_ID = \"gd_mcswdt6z2elth3zqr2\"        # AI Mode Google dataset\n",
    "BASE_URL = \"https://api.brightdata.com\"\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Trigger the dataset run\n",
    "payload = [\n",
    "    {\n",
    "        \"url\": \"https://google.com/aimode\",\n",
    "        \"prompt\": (\n",
    "            \"Act as an Instagram influencer discovery assistant. \"\n",
    "            \"Use the following Google query to find candidates: \"\n",
    "            \"site:instagram.com (\\\"pizza baker\\\" OR \\\"pizza blogger\\\" OR \\\"home pizza\\\" OR \\\"homemade pizza\\\") \"\n",
    "            \"(\\\"Lisbon\\\" OR \\\"Lisboa\\\") -restaurant -pizzeria -shop -menu -delivery. \"\n",
    "            \"From the results, identify Instagram creators based in Lisbon who consistently post homemade pizza content. \"\n",
    "            \"Focus on individuals rather than restaurants or commercial accounts, and prefer creators who share their own dough experiments, \"\n",
    "            \"baking techniques, and personal recipes. Exclude brands, shops, pizzerias, and SEO spam. \"\n",
    "            \"Return ONLY Instagram profile URLs in the exact format https://www.instagram.com/<handle>, one per line, with no additional text.\"\n",
    "        ),\n",
    "        \"country\": \"PT\",\n",
    "    }\n",
    "]\n",
    "\n",
    "r = requests.post(\n",
    "    f\"{BASE_URL}/datasets/v3/trigger\",\n",
    "    headers=headers,\n",
    "    params={\"dataset_id\": DATASET_ID, \"include_errors\": \"true\"},\n",
    "    json=payload,\n",
    ")\n",
    "\n",
    "if r.status_code == 400:\n",
    "    r = requests.post(\n",
    "        f\"{BASE_URL}/datasets/v3/trigger\",\n",
    "        headers=headers,\n",
    "        params={\"dataset_id\": DATASET_ID, \"include_errors\": \"true\"},\n",
    "        json={\"input\": payload},\n",
    "    )\n",
    "\n",
    "r.raise_for_status()\n",
    "print(\"Trigger raw text:\", trigger_resp.text)\n",
    "print(\"Trigger response:\", trigger_resp.status_code, trigger_resp.text)\n",
    "snapshot_id = r.json().get(\"snapshot_id\")\n",
    "\n",
    "# Poll progress until ready\n",
    "progress_url = f\"{BASE_URL}/datasets/v3/progress/{snapshot_id}\"\n",
    "\n",
    "while True:\n",
    "    p = requests.get(progress_url, headers=headers)\n",
    "    print(\"Progress raw:\", p.text[:300])\n",
    "    p.raise_for_status()\n",
    "    status = p.json().get(\"status\")\n",
    "    if status in {\"done\", \"completed\", \"ready\"}:\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "# Download results as JSON and save to file\n",
    "download_url = f\"{BASE_URL}/datasets/v3/snapshot/{snapshot_id}\"\n",
    "resp = requests.get(download_url, headers=headers, params={\"format\": \"json\"})\n",
    "resp.raise_for_status()\n",
    "\n",
    "data = resp.json()\n",
    "path = pathlib.Path(\"ai_google.json\")\n",
    "with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea608b",
   "metadata": {},
   "source": [
    "## 3. Perplecity → Instagram search (Bright data Web Scrapers Library)\n",
    "\n",
    "This code triggers a Perplexity-powered run via Bright Data’s Web Scrapers Library, polls progress and downloads the JSON results.  \n",
    "Instead of a strict Google query, you provide a short natural-language prompt. Perplexity does the discovery and the dataset returns the findings you can post-process (e.g., extract Instagram profile URLs).\n",
    "\n",
    "Prompt examples:\n",
    "- Find Instagram profiles of NYC sourdough bakers. Prefer individual bakers (not brands/agencies). Return profile URLs only.\n",
    "- Find Instagram creators in Europe who post about sustainable fashion. Return profile URLs only.\n",
    "- Find Instagram creators who are indie makers or solopreneurs and frequently post reels. Return profile URLs only.\n",
    "- Find Instagram profiles focused on AI tools and data engineering with authentic, human-made content. Return profile URLs only.\n",
    "- Find Instagram food bloggers in Tel Aviv who share step-by-step baking recipes. Prefer individuals, not shops. Return profile URLs only.\n",
    "- Find Instagram photographers in Berlin who shoot street/documentary style. Return profile URLs only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json, pathlib, requests\n",
    "\n",
    "API_KEY = os.getenv(\"BRIGHTDATA_API_TOKEN\")           \n",
    "DATASET_ID = \"gd_m7dhdot1vw9a7gc1n\"                  \n",
    "BASE_URL = \"https://api.brightdata.com\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Trigger the dataset run\n",
    "prompt = (\n",
    "    'Find Instagram profiles of NYC sourdough bakers. '\n",
    "    'Return 15 profile URLs only (one per line). '\n",
    "    'Prefer individual bakers (not brands or agencies). '\n",
    "    'NYC includes Manhattan, Brooklyn, Queens.'\n",
    ")\n",
    "\n",
    "payload = [{\"url\": \"https://www.perplexity.ai\", \"prompt\": prompt, \"index\": 1}]\n",
    "\n",
    "r = requests.post(\n",
    "    f\"{BASE_URL}/datasets/v3/trigger\",\n",
    "    headers=headers,\n",
    "    params={\"dataset_id\": DATASET_ID, \"include_errors\": \"true\"},\n",
    "    json={\"input\": payload},      \n",
    ")\n",
    "\n",
    "r.raise_for_status()\n",
    "print(\"Trigger raw text:\", trigger_resp.text)\n",
    "print(\"Trigger response:\", trigger_resp.status_code, trigger_resp.text)\n",
    "snapshot_id = r.json().get(\"snapshot_id\")\n",
    "\n",
    "# Poll progress until ready\n",
    "progress_url = f\"{BASE_URL}/datasets/v3/progress/{snapshot_id}\"\n",
    "while True:\n",
    "    p = requests.get(progress_url, headers=headers)\n",
    "    print(\"Progress raw:\", p.text[:300])\n",
    "    p.raise_for_status()\n",
    "    status = p.json().get(\"status\")\n",
    "    if status in {\"done\", \"completed\", \"ready\"}:\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "# Download results as JSON and save to file\n",
    "download_url = f\"{BASE_URL}/datasets/v3/snapshot/{snapshot_id}\"\n",
    "resp = requests.get(download_url, headers=headers, params={\"format\": \"json\"})\n",
    "resp.raise_for_status()\n",
    "\n",
    "data = resp.json()\n",
    "path = pathlib.Path(\"perplexity_bd.json\")\n",
    "with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b8f21",
   "metadata": {},
   "source": [
    "## 4. Direct call to perplexity (Openrouter)\n",
    "\n",
    "This code calls a Perplexity online model through OpenRouter to discover Instagram profiles and prints the extracted profile URLs.\n",
    "\n",
    "What it does:\n",
    "- initializes an OpenRouter provider using the OPENROUTER_API_KEY environment variable\n",
    "- selects a Perplexity model for web-enabled search\n",
    "- sets a system prompt that enforces output format: one Instagram profile URL per line, prefer individuals over brands\n",
    "- sends a user prompt: find NYC sourdough bakers on Instagram \n",
    "- runs the agent and captures plain-text output\n",
    "- extracts instagram.com/{username} URLs with a regex and prints the count and a preview\n",
    "\n",
    "Notes:\n",
    "- set OPENROUTER_API_KEY in your environment before running\n",
    "- adjust the model name or prompt to target different niches or locations\n",
    "- the regex keeps only profile-like URLs and ignores posts/reels/explore links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df984b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.openrouter import OpenRouterProvider\n",
    "\n",
    "provider = OpenRouterProvider(api_key=os.getenv(\"OPENROUTER_API_KEY\", ''))\n",
    "\n",
    "model = OpenAIChatModel(\n",
    "    \"perplexity/sonar-pro-search\",\n",
    "    provider=provider,\n",
    ")\n",
    "\n",
    "SYSTEM = \"\"\"\n",
    "You are an Instagram influencer discovery assistant.\n",
    "\n",
    "Output format rules (very important):\n",
    "- Return ONLY Instagram profile URLs.\n",
    "- One URL per line.\n",
    "- No bullet points, no numbering, no headings, no explanations.\n",
    "- Do NOT include @handles without URLs.\n",
    "- Do NOT include any text before or after the URLs.\n",
    "- Only include URLs for Instagram profiles confirmed by credible web sources.\n",
    "- If no verified URL is found, return an empty response—do not guess or fabricate any profiles.\n",
    "\n",
    "Valid output:\n",
    "https://www.instagram.com/username1\n",
    "https://www.instagram.com/username2\n",
    "\n",
    "Invalid output examples (never do this):\n",
    "1. @username - great creator\n",
    "@username\n",
    "Here are some creators: ...\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM,\n",
    ")\n",
    "\n",
    "PROMPT = (\n",
    "    \"Find Instagram creators based in New York City who consistently post sourdough bread baking content. \"\n",
    "    \"Focus on individuals, not bakeries, restaurants, or commercial accounts. \"\n",
    "    \"Prefer creators who share their own starter maintenance, dough experiments, baking techniques, and personal recipes. \"\n",
    "    \"Exclude brands, shops, bakeries, and SEO spam. \"\n",
    "    \"Only include accounts for which you have a verified direct URL to instagram.com from credible web sources. If you are not sure a handle exists, do not include it. \"\n",
    "    \"Return ONLY Instagram profile URLs in the exact format 'https://www.instagram.com/<handle>' one per line, with no additional text.\"\n",
    ")\n",
    "\n",
    "result = await agent.run(PROMPT)\n",
    "text = result.output\n",
    "\n",
    "urls = []\n",
    "for line in text.splitlines():\n",
    "    m = re.search(r\"(https?://(?:www\\.)?instagram\\.com/[A-Za-z0-9._]+)\", line.strip())\n",
    "    if m:\n",
    "        urls.append(m.group(1))\n",
    "print(len(urls), urls[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa0ed2",
   "metadata": {},
   "source": [
    "## 5. Hashtag → Perplexity chain for NYC sourdough bakers\n",
    "\n",
    "This code runs a two-step Perplexity flow via OpenRouter to find sourdough bakers on Instagram in New York City.\n",
    "\n",
    "What it does:\n",
    "- initializes an OpenRouter provider using `OPENROUTER_API_KEY`\n",
    "- configures the `perplexity/sonar-pro-search` model through `pydantic_ai`\n",
    "- uses a strict system prompt so the model returns only real `instagram.com/<handle>` profile URLs, one per line, with no extra text\n",
    "- first call: asks Perplexity for a JSON array of Instagram hashtags used by NYC sourdough bakers (with rationale and popularity notes)\n",
    "- parses the JSON and extracts the `hashtag` field from each item\n",
    "- second call: uses those hashtags to find individual creators in NYC who regularly post sourdough baking content, excluding brands, bakeries, and SEO spam\n",
    "- extracts and deduplicates profile URLs with a regex, then prints how many were found and the final list\n",
    "\n",
    "Notes:\n",
    "- set `OPENROUTER_API_KEY` in your environment before running\n",
    "- you can tweak the prompts to target other niches (pizza, pastry, coffee) or locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.openrouter import OpenRouterProvider\n",
    "\n",
    "provider = OpenRouterProvider(api_key=os.getenv(\"OPENROUTER_API_KEY\", \"\"))\n",
    "\n",
    "model = OpenAIChatModel(\n",
    "    \"perplexity/sonar-pro-search\",\n",
    "    provider=provider,\n",
    ")\n",
    "\n",
    "\n",
    "HASHTAG_SYSTEM = \"\"\"\n",
    "You are an Instagram hashtag research assistant.\n",
    "\n",
    "Return ONLY a pure JSON array.\n",
    "Each item must include:\n",
    "- \"hashtag\"\n",
    "- \"short_rationale\"\n",
    "- \"popularity_note\"\n",
    "\n",
    "No explanations, no text outside JSON.\n",
    "\"\"\"\n",
    "\n",
    "hashtag_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=HASHTAG_SYSTEM\n",
    ")\n",
    "\n",
    "HASHTAGS_PROMPT = (\n",
    "    \"Give me 10 Instagram hashtags used by sourdough bread bakers in New York City \"\n",
    "    \"in 2024-2025. Provide the results as a pure JSON array. \"\n",
    "    \"Each item must have fields: \\\"hashtag\\\", \\\"short_rationale\\\", \\\"popularity_note\\\". \"\n",
    "    \"Return only the JSON array — nothing else.\"\n",
    ")\n",
    "\n",
    "hashtags_result = await hashtag_agent.run(HASHTAGS_PROMPT)\n",
    "hashtags_json = hashtags_result.output\n",
    "\n",
    "hashtags = []\n",
    "try:\n",
    "    hashtags = json.loads(hashtags_json)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"JSON parsing failed. Raw output:\")\n",
    "    print(hashtags_json)\n",
    "\n",
    "hashtag_strings = [h[\"hashtag\"] for h in hashtags if \"hashtag\" in h]\n",
    "\n",
    "print(\"Extracted hashtags:\", hashtag_strings)\n",
    "\n",
    "\n",
    "INFLUENCER_SYSTEM = \"\"\"\n",
    "You are an Instagram influencer discovery assistant.\n",
    "\n",
    "Output rules:\n",
    "- Return ONLY Instagram profile URLs.\n",
    "- One URL per line.\n",
    "- No bullet points, no numbering.\n",
    "- No explanations.\n",
    "- No fake or unverified accounts.\n",
    "- Do not guess or hallucinate handles.\n",
    "\n",
    "Valid output example:\n",
    "https://www.instagram.com/username\n",
    "https://www.instagram.com/another.one\n",
    "\"\"\"\n",
    "\n",
    "influencer_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=INFLUENCER_SYSTEM\n",
    ")\n",
    "\n",
    "INFLUENCER_PROMPT = (\n",
    "    f\"Using the following hashtags: {hashtag_strings}, \"\n",
    "    \"Find Instagram creators based in New York City who consistently post sourdough bread baking content. \"\n",
    "    \"Focus on individuals, not bakeries, restaurants, or commercial accounts. \"\n",
    "    \"Prefer creators who share starter maintenance, dough experiments, baking techniques, and personal recipes. \"\n",
    "    \"Exclude brands, shops, bakeries, and SEO spam. \"\n",
    "    \"Return ONLY direct Instagram profile URLs in the format 'https://www.instagram.com/<handle>' \"\n",
    "    \"one per line with no extra text. \"\n",
    "    \"If unsure whether a handle exists, do not include it.\"\n",
    ")\n",
    "\n",
    "influencers_result = await influencer_agent.run(INFLUENCER_PROMPT)\n",
    "text = influencers_result.output\n",
    "\n",
    "\n",
    "urls = []\n",
    "for line in text.splitlines():\n",
    "    m = re.search(r\"(https?://(?:www\\.)?instagram\\.com/[A-Za-z0-9._/]+)\", line.strip())\n",
    "    if m:\n",
    "        urls.append(m.group(1))\n",
    "\n",
    "urls = list(dict.fromkeys(urls))\n",
    "\n",
    "print(\"Found influencers:\", len(urls))\n",
    "print(urls)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wykra-api-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
